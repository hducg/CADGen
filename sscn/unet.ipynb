{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sparseconvnet as scn\n",
    "import time\n",
    "import os, sys\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 training samples\n"
     ]
    }
   ],
   "source": [
    "data.init(24,24*8,1)\n",
    "dimension = 3\n",
    "reps = 1 #Conv block repetition factor\n",
    "m = 32 #Unet number of features\n",
    "nPlanes = [m, 2*m, 3*m, 4*m, 5*m] #UNet number of features per level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(data.nClassesTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (sparseModel): Sequential(\n",
      "    (0): InputLayer()\n",
      "    (1): SubmanifoldConvolution 1->32 C3\n",
      "    (2): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BatchNormLeakyReLU(32,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "        (1): SubmanifoldConvolution 32->32 C3\n",
      "      )\n",
      "      (1): ConcatTable(\n",
      "        (0): Identity()\n",
      "        (1): Sequential(\n",
      "          (0): BatchNormLeakyReLU(32,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "          (1): Convolution 32->64 C2/2\n",
      "          (2): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): BatchNormLeakyReLU(64,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "              (1): SubmanifoldConvolution 64->64 C3\n",
      "            )\n",
      "            (1): ConcatTable(\n",
      "              (0): Identity()\n",
      "              (1): Sequential(\n",
      "                (0): BatchNormLeakyReLU(64,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                (1): Convolution 64->96 C2/2\n",
      "                (2): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): BatchNormLeakyReLU(96,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                    (1): SubmanifoldConvolution 96->96 C3\n",
      "                  )\n",
      "                  (1): ConcatTable(\n",
      "                    (0): Identity()\n",
      "                    (1): Sequential(\n",
      "                      (0): BatchNormLeakyReLU(96,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                      (1): Convolution 96->128 C2/2\n",
      "                      (2): Sequential(\n",
      "                        (0): Sequential(\n",
      "                          (0): BatchNormLeakyReLU(128,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                          (1): SubmanifoldConvolution 128->128 C3\n",
      "                        )\n",
      "                        (1): ConcatTable(\n",
      "                          (0): Identity()\n",
      "                          (1): Sequential(\n",
      "                            (0): BatchNormLeakyReLU(128,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                            (1): Convolution 128->160 C2/2\n",
      "                            (2): Sequential(\n",
      "                              (0): Sequential(\n",
      "                                (0): BatchNormLeakyReLU(160,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                                (1): SubmanifoldConvolution 160->160 C3\n",
      "                              )\n",
      "                            )\n",
      "                            (3): BatchNormLeakyReLU(160,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                            (4): Deconvolution 160->128 C2/2\n",
      "                          )\n",
      "                        )\n",
      "                        (2): JoinTable()\n",
      "                        (3): Sequential(\n",
      "                          (0): BatchNormLeakyReLU(256,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                          (1): SubmanifoldConvolution 256->128 C3\n",
      "                        )\n",
      "                      )\n",
      "                      (3): BatchNormLeakyReLU(128,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                      (4): Deconvolution 128->96 C2/2\n",
      "                    )\n",
      "                  )\n",
      "                  (2): JoinTable()\n",
      "                  (3): Sequential(\n",
      "                    (0): BatchNormLeakyReLU(192,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                    (1): SubmanifoldConvolution 192->96 C3\n",
      "                  )\n",
      "                )\n",
      "                (3): BatchNormLeakyReLU(96,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "                (4): Deconvolution 96->64 C2/2\n",
      "              )\n",
      "            )\n",
      "            (2): JoinTable()\n",
      "            (3): Sequential(\n",
      "              (0): BatchNormLeakyReLU(128,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "              (1): SubmanifoldConvolution 128->64 C3\n",
      "            )\n",
      "          )\n",
      "          (3): BatchNormLeakyReLU(64,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "          (4): Deconvolution 64->32 C2/2\n",
      "        )\n",
      "      )\n",
      "      (2): JoinTable()\n",
      "      (3): Sequential(\n",
      "        (0): BatchNormLeakyReLU(64,eps=0.0001,momentum=0.9,affine=True,leakiness=0)\n",
      "        (1): SubmanifoldConvolution 64->32 C3\n",
      "      )\n",
      "    )\n",
      "    (3): BatchNormReLU(32,eps=0.0001,momentum=0.9,affine=True)\n",
      "    (4): OutputLayer()\n",
      "  )\n",
      "  (linear): Linear(in_features=32, out_features=25, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.sparseModel = scn.Sequential().add(\n",
    "           scn.InputLayer(dimension, data.spatialSize, mode=3)).add(\n",
    "           scn.SubmanifoldConvolution(dimension, 1, m, 3, False)).add(\n",
    "           scn.UNet(dimension, reps, nPlanes, residual_blocks=False, downsample=[2,2])).add(\n",
    "           scn.BatchNormReLU(m)).add(\n",
    "           scn.OutputLayer(dimension))\n",
    "        self.linear = nn.Linear(m, data.nClassesTotal)\n",
    "    def forward(self,x):\n",
    "        x=self.sparseModel(x)\n",
    "        x=self.linear(x)\n",
    "        return x\n",
    "\n",
    "model=Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../dataset/machining_feature/points/0-0-23.pts', '../../dataset/machining_feature/points/0-4-23.pts', '../../dataset/machining_feature/points/0-8-23.pts', '../../dataset/machining_feature/points/0-7-23.pts']\n",
      "['../../dataset/machining_feature/points/0-6-23.pts', '../../dataset/machining_feature/points/0-2-23.pts', '../../dataset/machining_feature/points/0-1-23.pts', '../../dataset/machining_feature/points/0-3-23.pts']\n"
     ]
    }
   ],
   "source": [
    "trainIterator=data.train()\n",
    "validIterator=data.valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[102,  70, 131,   0],\n",
      "        [102,  70, 131,   0],\n",
      "        [102,  71, 131,   0],\n",
      "        [101,  71, 131,   0],\n",
      "        [101,  71, 131,   0],\n",
      "        [101,  71, 131,   0],\n",
      "        [101,  71, 131,   0],\n",
      "        [100,  71, 131,   0],\n",
      "        [100,  71, 131,   0],\n",
      "        [103,  70, 131,   0]])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24])\n",
      "../../dataset/machining_feature/points/0-8-23.pts\n",
      "26480\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(trainIterator))\n",
    "for x in batch['x']:\n",
    "    print(x[200:210])\n",
    "print(batch['y'][200:210])\n",
    "for xf in batch['xf']:\n",
    "    print(xf)\n",
    "for n in batch['nPoints']:\n",
    "    print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': 1, 'initial_lr': 0.1, 'lr_decay': 0.04, 'weight_decay': 0.0001, 'momentum': 0.9, 'check_point': False, 'use_cuda': False, 'epoch': 1}\n",
      "#parameters 3840409\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "p={}\n",
    "p['n_epochs'] = 1\n",
    "p['initial_lr'] = 1e-1\n",
    "p['lr_decay'] = 4e-2\n",
    "p['weight_decay'] = 1e-4\n",
    "p['momentum'] = 0.9\n",
    "p['check_point'] = False\n",
    "p['use_cuda'] = torch.cuda.is_available()\n",
    "dtype = 'torch.cuda.FloatTensor' if p['use_cuda'] else 'torch.FloatTensor'\n",
    "dtypei = 'torch.cuda.LongTensor' if p['use_cuda'] else 'torch.LongTensor'\n",
    "if p['use_cuda']:\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "    lr=p['initial_lr'],\n",
    "    momentum = p['momentum'],\n",
    "    weight_decay = p['weight_decay'],\n",
    "    nesterov=True)\n",
    "if p['check_point'] and os.path.isfile('epoch.pth'):\n",
    "    p['epoch'] = torch.load('epoch.pth') + 1\n",
    "    print('Restarting at epoch ' +\n",
    "          str(p['epoch']) +\n",
    "          ' from model.pth ..')\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "else:\n",
    "    p['epoch']=1\n",
    "print(p)\n",
    "print('#parameters', sum([x.nelement() for x in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(stats,batch,predictions,loss):\n",
    "    ctr=0\n",
    "    for nP,f in zip(batch['nPoints'],batch['xf']):\n",
    "        f=f.split('/')[-1]\n",
    "        if not f in stats:\n",
    "            stats[f]={'p': 0, 'y': 0}\n",
    "        #print(predictions[ctr:ctr+nP,classOffset:classOffset+nClasses].abs().max().item())\n",
    "        stats[f]['p']+=predictions.detach()[ctr:ctr+nP].cpu().numpy()\n",
    "        stats[f]['y']=batch['y'].detach()[ctr:ctr+nP].cpu().numpy()\n",
    "        ctr+=nP\n",
    "\n",
    "def inter(pred, gt, label):\n",
    "    assert pred.size == gt.size, 'Predictions incomplete!'\n",
    "    return np.sum(np.logical_and(pred.astype('int') == label, gt.astype('int') == label))\n",
    "\n",
    "def union(pred, gt, label):\n",
    "    assert pred.size == gt.size, 'Predictions incomplete!'\n",
    "    return np.sum(np.logical_or(pred.astype('int') == label, gt.astype('int') == label))\n",
    "\n",
    "def iou(stats):\n",
    "    eps = sys.float_info.epsilon\n",
    "    \n",
    "    nmodels = len(stats)\n",
    "    pred = []\n",
    "    gt = []\n",
    "    for j in stats.values():\n",
    "        pred.append(j['p'].argmax(1))\n",
    "        gt.append(j['y'])\n",
    "    npart = np.max(np.concatenate(gt))+1\n",
    "    iou_per_part = np.zeros((len(pred), npart))\n",
    "    # loop over parts\n",
    "    for j in range(npart):\n",
    "        # loop over CAD models\n",
    "        for k in range(len(pred)):\n",
    "            p = pred[k]\n",
    "            iou_per_part[k, j] = (inter(p, gt[k], j) + eps) / (union(p, gt[k], j) + eps)\n",
    "    # average over CAD models and parts\n",
    "    iou_all = np.mean(iou_per_part)\n",
    "    return {'nmodels_sum': nmodels, 'iou': iou_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37702\n",
      "26480\n",
      "32148\n",
      "31632\n",
      "train epoch 1 1 iou= 0.9048107445534499 MegaMulAdd= 223.485456 MegaHidden 0.369216 time= 0.6727063655853271 s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(p['epoch'], p['n_epochs'] + 1):\n",
    "    model.train()\n",
    "    stats = {}\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = p['initial_lr'] * \\\n",
    "        math.exp((1 - epoch) * p['lr_decay'])\n",
    "    scn.forward_pass_multiplyAdd_count=0\n",
    "    scn.forward_pass_hidden_states=0\n",
    "    start = time.time()\n",
    "    for batch in trainIterator:\n",
    "        optimizer.zero_grad()\n",
    "        batch['x'][1]=batch['x'][1].type(dtype)\n",
    "        batch['y']=batch['y'].type(dtypei)\n",
    "        predictions=model(batch['x'])\n",
    "        print(len(predictions))\n",
    "        loss = criterion.forward(predictions,batch['y'])\n",
    "        store(stats,batch,predictions,loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    r = iou(stats)\n",
    "    print('train epoch',epoch,1,'iou=', r['iou'], 'MegaMulAdd=',scn.forward_pass_multiplyAdd_count/r['nmodels_sum']/1e6, 'MegaHidden',scn.forward_pass_hidden_states/r['nmodels_sum']/1e6,'time=',time.time() - start,'s')\n",
    "\n",
    "    if p['check_point']:\n",
    "        torch.save(epoch, 'epoch.pth')\n",
    "        torch.save(model.state_dict(),'model.pth')\n",
    "\n",
    "    if epoch in [10,30,100]:\n",
    "        model.eval()\n",
    "        stats = {}\n",
    "        scn.forward_pass_multiplyAdd_count=0\n",
    "        scn.forward_pass_hidden_states=0\n",
    "        start = time.time()\n",
    "        for rep in range(1,1+3):\n",
    "            for batch in validIterator:\n",
    "                batch['x'][1]=batch['x'][1].type(dtype)\n",
    "                batch['y']=batch['y'].type(dtypei)\n",
    "                predictions=model(batch['x'])\n",
    "                loss = criterion.forward(predictions,batch['y'])\n",
    "                store(stats,batch,predictions,loss)\n",
    "            r = iou(stats)\n",
    "            print('valid epoch',epoch,rep,'iou=', r['iou'], 'MegaMulAdd=',scn.forward_pass_multiplyAdd_count/r['nmodels_sum']/1e6, 'MegaHidden',scn.forward_pass_hidden_states/r['nmodels_sum']/1e6,'time=',time.time() - start,'s')\n",
    "        print(r['iou'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
